---
title: "Sentiment Analysis of Spotify, Amazon Music and Pandora user reviews"
output:
  html_document:
    df_print: paged
---

The datasets include almost 40,000 user reviews on Spotify, Amazon Music and Pandora collected from Trustpilot. Sentiment analysis is conducted to get an overview of users' opinion on the three products and compare sentiment for each app in terms of subscription fee, UX/UI, music catalog and app integration with smart devices. 

```{r message=FALSE, warning=FALSE, result="hide"}
library(tidytext)
library(dplyr)
library(ggplot2)
library(stringr)
library(tm)
library(qdap)
library(tidyr)
library(igraph)
library(ggraph)
```

Load the data

```{r}
spotify <- read.csv("E:/MSBA/1 Aligning IS/Final project/spotify.csv", stringsAsFactors = FALSE)
str(spotify)

pandora <- read.csv("E:/MSBA/1 Aligning IS/Final project/pandora.csv", stringsAsFactors = FALSE)
str(pandora)

amazon <- read.csv("E:/MSBA/1 Aligning IS/Final project/amazon.csv", stringsAsFactors = FALSE)
str(amazon)
```

## Data cleaning

```{r}
#Tokenize sentences
tidy_spotify <- spotify %>% unnest_tokens(word, Review)
tidy_amazon <- amazon %>% unnest_tokens(word, Review)
tidy_pandora <- pandora %>% unnest_tokens(word, Review)
```

Remove stop words, i.e. words that deliver little to no value in sentiment assessment. We will use the pre-built "english" dictionary of stopwords, including words as listed below: 

```{r fig.width=15}
stopwords("en")
```

Remove using a cleaning function: 

```{r}
new_stopword_list <- c("ря", "zря", "fря", "ряz", "в", "NA", "ряz", "s", "ряs", " oря", "oря", "ря'o", "sря", "^ря", "sря", "ря") #character errors
stop_words <- c(stopwords("en"), new_stopword_list)

cleaner <- function(x){
  filter(x, !word %in% stop_words)
}
tidy_spotify <- cleaner(tidy_spotify)
tidy_amazon <- cleaner(tidy_amazon)
tidy_pandora <- cleaner(tidy_pandora)
```


## Sentiment analysis

We will use 3 popular lexicons nrc, bing and afinn to assign numerical values to each word. The sum of these values for each review will be used for classifying whether a review is positive, negative or neutral. 

```{r}
#Get lexicons
get_sentiments(lexicon="nrc")
get_sentiments(lexicon="bing")
get_sentiments(lexicon="afinn")
```


```{r}
#Joining the lexicons
##Spotify 
nrc_sentiment <- tidy_spotify %>% inner_join(get_sentiments("nrc"), by = "word")
bing_sentiment <- tidy_spotify %>% inner_join(get_sentiments("bing"),
                                             by = "word")
afinn_sentiment <- tidy_spotify %>% inner_join(get_sentiments("afinn"),
                                              by = "word")
##Amazon  
nrc_sentiment <- tidy_amazon %>% inner_join(get_sentiments("nrc"), by = "word")
bing_sentiment <- tidy_amazon %>% inner_join(get_sentiments("bing"),
                                                by = "word")
afinn_sentiment <- tidy_amazon %>% inner_join(get_sentiments("afinn"),
                                                 by = "word")
##Pandora 
nrc_sentiment <- tidy_pandora %>% inner_join(get_sentiments("nrc"), by = "word")
bing_sentiment <- tidy_pandora %>% inner_join(get_sentiments("bing"),
                                                by = "word")
afinn_sentiment <- tidy_pandora %>% inner_join(get_sentiments("afinn"),
                                                 by = "word")
```


```{r}
#Aggregate review-level popularity information
nrc_sentiment$score <- ifelse(nrc_sentiment$sentiment == "negative", -1, 1)
nrc_aggregate <- nrc_sentiment %>% select(ID, score) %>%
  group_by(ID) %>% summarise(nrc_score = sum(score))

bing_sentiment$score <- ifelse(bing_sentiment$sentiment == "negative", -1, 1)
bing_aggregate <- bing_sentiment %>% select(ID, score) %>%
  group_by(ID) %>% summarise(bing_score = sum(score))

afinn_aggregate <- afinn_sentiment %>% select(ID, score) %>%
  group_by(ID) %>% summarise(afinn_score = sum(score))
```


```{r}
#Aggregate sentiment info to the original dataset
spotify_sent <- merge(x = spotify, y = nrc_aggregate, all.x = TRUE, by = "ID")
spotify_sent <- merge(x = spotify_sent, y = bing_aggregate, all.x = TRUE, by = "ID")
spotify_sent <- merge(x = spotify_sent, y = afinn_aggregate, all.x = TRUE, by = "ID")
spotify_sent[is.na(spotify_sent)] <- 0

amazon_sent <- merge(x = amazon, y = nrc_aggregate, all.x = TRUE, by = "ID")
amazon_sent <- merge(x = amazon_sent, y = bing_aggregate, all.x = TRUE, by = "ID")
amazon_sent <- merge(x = amazon_sent, y = afinn_aggregate, all.x = TRUE, by = "ID")
amazon_sent[is.na(amazon_sent)] <- 0

pandora_sent <- merge(x = pandora, y = nrc_aggregate, all.x = TRUE, by = "ID")
pandora_sent <- merge(x = pandora_sent, y = bing_aggregate, all.x = TRUE, by = "ID")
pandora_sent <- merge(x = pandora_sent, y = afinn_aggregate, all.x = TRUE, by = "ID")
pandora_sent[is.na(pandora_sent)] <- 0
```

Denote review sentiment:
 
```{r}
#Denote review sentiment
##Spotify
  spotify_sent$afinn_judgement <- ifelse(spotify_sent$afinn_score < 0, "negative",
                                      ifelse(spotify_sent$afinn_score > 0, "positive", "neutral"))
  spotify_sent$bing_judgement <- ifelse(spotify_sent$bing_score < 0, "negative",
                                     ifelse(spotify_sent$bing_score > 0, "positive", "neutral"))
  spotify_sent$nrc_judgement <- ifelse(spotify_sent$nrc_score < 0, "negative",
                                    ifelse(spotify_sent$nrc_score > 0, "positive", "neutral"))
  rowSums(table(spotify_sent$bing_judgement, spotify_sent$bing_score))
```


```{r}
##Amazon
  amazon_sent$afinn_judgement <- ifelse(amazon_sent$afinn_score < 0, "negative",
                                         ifelse(amazon_sent$afinn_score > 0, "positive", "neutral"))
  amazon_sent$bing_judgement <- ifelse(amazon_sent$bing_score < 0, "negative",
                                        ifelse(amazon_sent$bing_score > 0, "positive", "neutral"))
  amazon_sent$nrc_judgement <- ifelse(amazon_sent$nrc_score < 0, "negative",
                                       ifelse(amazon_sent$nrc_score > 0, "positive", "neutral"))
  rowSums(table(amazon_sent$bing_judgement, amazon_sent$bing_score))
```


```{r}
##Pandora
  pandora_sent$afinn_judgement <- ifelse(pandora_sent$afinn_score < 0, "negative",
                                         ifelse(pandora_sent$afinn_score > 0, "positive", "neutral"))
  pandora_sent$bing_judgement <- ifelse(pandora_sent$bing_score < 0, "negative",
                                        ifelse(pandora_sent$bing_score > 0, "positive", "neutral"))
  pandora_sent$nrc_judgement <- ifelse(pandora_sent$nrc_score < 0, "negative",
                                       ifelse(pandora_sent$nrc_score > 0, "positive", "neutral"))
  rowSums(table(pandora_sent$bing_judgement, pandora_sent$bing_score))
```

## Sentiment contribution

Let's see which words contribute the most positive/negative sentiment on each app:

Spotify:

```{r}
bing_wc <- function(x){
  x %>%
    inner_join(get_sentiments("bing"), by = "word") %>%
    count(word, sentiment, sort = TRUE) %>%
    ungroup() %>%
    group_by(sentiment) %>%
    top_n(10) %>%
    ungroup() %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n, fill = sentiment)) +
     geom_col(show.legend = FALSE) +
     facet_wrap(~sentiment, scales = "free_y") +
     labs(y = "Contribution to sentiment",
     x = NULL) +
     coord_flip()
}
```

See which words contribute the most to positive/negative sentiment on Spotify: 

```{r fig.width=10}
bing_wc(tidy_spotify)
```

Amazon:

```{r fig.width=10}
bing_wc(tidy_amazon)
```

And Pandora: 

```{r fig.width=10}
bing_wc(tidy_pandora)
```

## Word cloud

Word cloud is a helpful plot of the most frequent words in a text. Let's see what people say the most about each app. 

```{r fig.width=10}
library(wordcloud)
c_wordcloud <- function(i){
  i %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 150, rot.per=0.1, scale = c(6,1), colors=brewer.pal(8, "Dark2")))
}
```

Spotify's word cloud:

```{r fig.width=15}
c_wordcloud(tidy_spotify)
```

Amazon's word cloud:

```{r fig.width=15}
c_wordcloud(tidy_amazon)
```

Pandora's word cloud: 

```{r fig.width=15}
c_wordcloud(tidy_pandora)
```

## Check review sentiment on specific topics

#### Price sentiment
Let's see how many percent of the reviews on price/subscription fee of each app are positive: 

```{r}
#Check price sentiment 
spotifyPrice <- grepl("cost| subscription| price| fee| premium| worth| money| pay| paid| pricing", spotify_sent$Review, ignore.case = TRUE)
sdf <- data.frame(sentiment = spotify_sent$bing_judgement, related_words = spotifyPrice)
sp = sum(sdf$related_words == "TRUE" & sdf$sentiment == "positive")/sum(sdf$related_words == "TRUE")*100
cat("Spotify price =", sp,"%
")

amazonPrice <- grepl("cost| subscription| price| fee| premium| worth| money| pay| paid| pricing", amazon_sent$Review, ignore.case = TRUE)
adf <- data.frame(sentiment = amazon_sent$bing_judgement, related_words = amazonPrice)
ap = sum(adf$related_words == "TRUE" & adf$sentiment == "positive")/sum(adf$related_words == "TRUE")*100
cat("Amazon price =", ap,"%
")
pandoraPrice <- grepl("cost| subscription| price| fee| premium| worth| money| pay| paid| pricing", pandora_sent$Review, ignore.case = TRUE)
pdf <- data.frame(sentiment = pandora_sent$bing_judgement, related_words = pandoraPrice)
pp = sum(pdf$related_words == "TRUE" & pdf$sentiment == "positive")/sum(pdf$related_words == "TRUE")*100
cat("Pandora price =", pp,"%")
```

#### UX/UI

```{r}
#Check UX/UI sentiment
spotifyUX <- grepl("functionality|UI|UX|experience|user experience|user interface|interface|usability|utility|app|glitch|device", spotify_sent$Review, ignore.case = TRUE)
sux <- data.frame(sentiment = spotify_sent$bing_judgement, related_words = spotifyUX)
su <- sum(sdf$related_words == "TRUE" & sdf$sentiment == "positive")/sum(sdf$related_words == "TRUE")*100
cat("Spotify UX =", su,"%
")

amazonUX <- grepl("functionaliyu|UI|UX|experience|user experience|user interface|interface|usability|utility|app|glitch|device", amazon_sent$Review, ignore.case = TRUE)
aux <- data.frame(sentiment = amazon_sent$bing_judgement, related_words = amazonUX)
au <- sum(aux$related_words == "TRUE" & aux$sentiment == "positive")/sum(aux$related_words == "TRUE")*100
cat("Amazon UX =", sp,"%
")
pandoraUX <- grepl("functionality|UI|UX|experience|user experience|user interface|interface|usability|utility|app|glitch|device", pandora_sent$Review, ignore.case = TRUE)
pux <- data.frame(sentiment = pandora_sent$bing_judgement, related_words = pandoraUX)
pu <- sum(pux$related_words == "TRUE" & pux$sentiment == "positive")/sum(pux$related_words == "TRUE")*100
cat("Pandora UX", pu,"%")
```

#### Music catalog

```{r}
#Check music catalog 
##Spotify
spotifyMusic <- grepl("music selection| selection| music| customized| playlist| recommendation| AI| discovery| variety| song| songs| library| broad| wide| range| catalogue| list| singers", 
                        spotify_sent$Review, ignore.case = TRUE)
sm <- data.frame(sentiment = spotify_sent$bing_judgement, related_words = spotifyMusic)
smc <- sum(sm$related_words == "TRUE" & sm$sentiment == "positive")/sum(sm$related_words == "TRUE")*100
cat("Spotify catalog =", smc,"%
")

##Amzon
amazonMusic <- grepl("music selection| selection| music| customized| playlist| recommendation| AI| discovery| variety| song| songs| library| broad| wide| range| catalogue| list| singers", 
                       amazon_sent$Review, ignore.case = TRUE)
amusic <- data.frame(sentiment = amazon_sent$bing_judgement, related_words = amazonMusic)
amc <- sum(amusic$related_words == "TRUE" & amusic$sentiment == "positive")/sum(amusic$related_words == "TRUE")*100
cat("Amazon catalog =", amc,"%
")

##Pandora
pandoraMusic <- pandoraMusic <- grepl("music selection| selection| music| customized| playlist| recommendation| AI| discovery| variety| song| songs| library| broad| wide| range| catalogue| list| singers", 
                                        pandora_sent$Review, ignore.case = TRUE)
pmusic <- data.frame(sentiment = pandora_sent$bing_judgement, related_words = pandoraMusic)
pmc <- sum(pmusic$related_words == "TRUE" & pmusic$sentiment == "positive")/sum(pmusic$related_words == "TRUE")*100
cat("Pandora catalog =", pmc,"%")
```

#### App's integration with smart devices

```{r}
#Check integration 
spotifyIn <- grepl("device| connection| connect| speaker| smart speaker| alexa| google home| siri| echo| integrate| integration| seamless| across| sync| synchronize| synchronization| bluetooth| strong| car| headphone| earphone| phone| airpod", 
                   spotify_sent$Review, ignore.case = TRUE)
si <- data.frame(sentiment = spotify_sent$bing_judgement, related_words = spotifyIn)
s <- sum(si$related_words == "TRUE" & si$sentiment == "positive")/sum(si$related_words == "TRUE")*100
cat("Spotify integration =", s,"%
")

amazonIn <- grepl("device| connection| connect| speaker| smart speaker| alexa| google home| siri| echo| integrate| integration| seamless| across| sync| synchronize| synchronization| bluetooth| strong| car| headphone| earphone| phone| airpod", 
                   amazon_sent$Review, ignore.case = TRUE)
ai <- data.frame(sentiment = amazon_sent$bing_judgement, related_words = amazonIn)
a <- sum(ai$related_words == "TRUE" & ai$sentiment == "positive")/sum(ai$related_words == "TRUE")*100
cat("Amazon integration =", a,"%
")

pandoraIn <- grepl("device| connection| connect| speaker| smart speaker| alexa| google home| siri| echo| integrate| integration| seamless| across| sync| synchronize| synchronization| bluetooth| strong| car| headphone| earphone| phone| airpod", 
                  pandora_sent$Review, ignore.case = TRUE)
pi <- data.frame(sentiment = pandora_sent$bing_judgement, related_words = pandoraIn)
p <- sum(pi$related_words == "TRUE" & pi$sentiment == "positive")/sum(pi$related_words == "TRUE")*100
cat("Pandora integration =", p, "%")
```

## N-gram and word network visualization

N-gram is a useful technique to see which words often go together in the document, so that we can make more sense of the text's content. Here we will start with bigrams (pairs of words). 

```{r}
#Word clustering using bigrams
library(tidyr)
bi_graph <- subset(spotify_sent, bing_judgement == "positive")
app_bigram <- bi_graph %>% unnest_tokens(bigram, Review, token = "ngrams", n = 2)

##Separate 
bigrams_separated <- app_bigram %>% 
    separate(bigram, c("word1", "word2"), sep = " ")

##Filter 
bigrams_filtered <- bigrams_separated %>%
    filter(!word1 %in% stop_words) %>%
    filter(!word2 %in% stop_words)

##New bigram counts:
bigram_counts <- bigrams_filtered %>%
    count(word1, word2, sort = TRUE)
  
##Unite
bigrams_united <- bigrams_filtered %>%
    unite(bigram, word1, word2, sep = " ")
```



```{r}
##Visualize bigrams 
  ### filter for only relatively common combinations
bigram_graph <- bigram_counts %>%
    filter(n > 10) %>%
    graph_from_data_frame() 
bigram_graph
```


```{r fig.width=15}
##void-themed graph 
  set.seed(1)
  a <- grid::arrow(type = "closed", length = unit(0.15, "inches"))
  ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(show.legend = FALSE,
                   end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "seagreen3", size = 3) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void() + 
  labs(title="Spotify bigrams")
```

With Amazon:


```{r fig.width=15, fig.height=6}
#Word clustering using bigrams
library(tidyr)
bi_graph <- subset(amazon_sent, bing_judgement == "positive")
app_bigram <- bi_graph %>% unnest_tokens(bigram, Review, token = "ngrams", n = 2) 
app_bigram %>%
  count(bigram, sort = TRUE)

##Separate 
bigrams_separated <- app_bigram %>% 
    separate(bigram, c("word1", "word2"), sep = " ")

##Filter 
bigrams_filtered <- bigrams_separated %>%
    filter(!word1 %in% stop_words) %>%
    filter(!word2 %in% stop_words)
##New bigram counts:
bigram_counts <- bigrams_filtered %>% 
    count(word1, word2, sort = TRUE)
  
##Unite
bigrams_united <- bigrams_filtered %>%
    unite(bigram, word1, word2, sep = " ")

##Visualize
bigram_graph <- bigram_counts %>%
    filter(n > 20) %>%
    graph_from_data_frame()

##void-themed graph 
set.seed(2)
a <- grid::arrow(type = "closed", length = unit(0.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(show.legend = FALSE,
                   end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "orange", size = 3) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void() + 
  labs(title="Amazon bigrams")
```

And Pandora:

```{r fig.width=15, fig.height=6}
#Word clustering using bigrams
library(tidyr)
bi_graph <- subset(pandora_sent, bing_judgement == "positive")
app_bigram <- bi_graph %>% unnest_tokens(bigram, Review, token = "ngrams", n = 2) 
app_bigram %>%
  count(bigram, sort = TRUE)

##Separate 
bigrams_separated <- app_bigram %>% 
    separate(bigram, c("word1", "word2"), sep = " ")

##Filter 
bigrams_filtered <- bigrams_separated %>%
    filter(!word1 %in% stop_words) %>%
    filter(!word2 %in% stop_words)
##New bigram counts:
bigram_counts <- bigrams_filtered %>% 
    count(word1, word2, sort = TRUE)
  
##Unite
bigrams_united <- bigrams_filtered %>%
    unite(bigram, word1, word2, sep = " ")

##Visualize
bigram_graph <- bigram_counts %>%
    filter(n > 25) %>%
    graph_from_data_frame()

##void-themed graph 
set.seed(2)
a <- grid::arrow(type = "closed", length = unit(0.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(show.legend = FALSE,
                   end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "skyblue3", size = 3) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void() + 
  labs(title="Pandora bigrams")
```






